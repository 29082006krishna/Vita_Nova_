{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "927f2d47-9b44-4393-86b5-8cf130b2367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# IMPORTS\n",
    "# =============================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da67a6db-234d-4ade-9ca1-3f93c433a3e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'diary_product.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdiary_product.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Ensure Date column is datetime\u001b[39;00m\n\u001b[32m      4\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(df[\u001b[33m'\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'diary_product.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dairy_product.csv\")\n",
    "\n",
    "# Ensure Date column is datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "220e8aa3-d9b1-4a85-b1af-3d6364d51628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Product Name:  Curd\n",
      "Enter State:  Gujarat\n",
      "Enter number of months to forecast (3, 6, 12):  12\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m state_name = \u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEnter State: \u001b[39m\u001b[33m\"\u001b[39m).strip()\n\u001b[32m      6\u001b[39m months_ahead = \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEnter number of months to forecast (3, 6, 12): \u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m df_product = \u001b[43mdf\u001b[49m[\n\u001b[32m      9\u001b[39m     (df[\u001b[33m'\u001b[39m\u001b[33mProduct Name\u001b[39m\u001b[33m'\u001b[39m] == product_name) &\n\u001b[32m     10\u001b[39m     (df[\u001b[33m'\u001b[39m\u001b[33mLocation\u001b[39m\u001b[33m'\u001b[39m] == state_name)\n\u001b[32m     11\u001b[39m ].copy()\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df_product.empty:\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo data found for product \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproduct_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m in state \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================\n",
    "# Step 2: User Input\n",
    "# =============================\n",
    "product_name = input(\"Enter Product Name: \").strip()\n",
    "state_name = input(\"Enter State: \").strip()\n",
    "months_ahead = int(input(\"Enter number of months to forecast (3, 6, 12): \"))\n",
    "\n",
    "df_product = df[\n",
    "    (df['Product Name'] == product_name) &\n",
    "    (df['Location'] == state_name)\n",
    "].copy()\n",
    "\n",
    "if df_product.empty:\n",
    "    raise ValueError(f\"No data found for product '{product_name}' in state '{state_name}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca0be3b-4d29-4d6b-a4d3-7c565f841064",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================\n",
    "# Step 3: External + Seasonal Features\n",
    "# =============================\n",
    "df_product['Month'] = df_product['Date'].dt.month\n",
    "df_product['Day'] = df_product['Date'].dt.day\n",
    "df_product['DayOfWeek'] = df_product['Date'].dt.dayofweek\n",
    "\n",
    "df_product_model = df_product[\n",
    "    [\n",
    "        'Quantity Sold (liters/kg)',\n",
    "        'Reorder Quantity (liters/kg)',\n",
    "        'Month',\n",
    "        'Day',\n",
    "        'DayOfWeek'\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "# Scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df_product_model.values)\n",
    "\n",
    "# =============================\n",
    "# Sequence Creation\n",
    "# =============================\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        xs.append(data[i:i+seq_length])\n",
    "        ys.append(data[i+seq_length][:2])  # predict only sales & demand\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "SEQ_LENGTH = 30\n",
    "X, y = create_sequences(scaled_data, SEQ_LENGTH)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(X_train, y_train), batch_size=32, shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    TensorDataset(X_test, y_test), batch_size=32, shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c198e674-2edb-476c-bfb2-1228d57d2d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================\n",
    "# Step 4: Hybrid Attention LSTM + Transformer\n",
    "# =============================\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        weights = torch.softmax(self.attn(x), dim=1)\n",
    "        return torch.sum(weights * x, dim=1)\n",
    "\n",
    "class HybridForecastModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=50, num_layers=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.attention = AttentionLayer(hidden_size)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_size,\n",
    "            nhead=5,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "\n",
    "        self.fc_mu = nn.Linear(hidden_size, 2)\n",
    "        self.fc_sigma = nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(2, x.size(0), 50)\n",
    "        c0 = torch.zeros(2, x.size(0), 50)\n",
    "\n",
    "        lstm_out, _ = self.lstm(x, (h0, c0))\n",
    "        attn_out = self.attention(lstm_out)\n",
    "        trans_out = self.transformer(attn_out.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        mu = self.fc_mu(trans_out)\n",
    "        sigma = torch.exp(self.fc_sigma(trans_out))\n",
    "\n",
    "        return mu, sigma\n",
    "\n",
    "model = HybridForecastModel(input_size=X_train.shape[2])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# =============================\n",
    "# Probabilistic Loss\n",
    "# =============================\n",
    "def gaussian_nll(mu, sigma, y):\n",
    "    return torch.mean(torch.log(sigma) + ((y - mu) ** 2) / (2 * sigma ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f43784-ce38-48c5-b706-8042f2725bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================\n",
    "# Step 5: Training\n",
    "# =============================\n",
    "EPOCHS = 50\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        mu, sigma = model(xb)\n",
    "        loss = gaussian_nll(mu, sigma, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca23bb5-dc6b-40f1-9003-0d7ed37669d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================\n",
    "# Step 6: Test Prediction\n",
    "# =============================\n",
    "model.eval()\n",
    "mu_test, _ = model(X_test)\n",
    "predicted_test = scaler.inverse_transform(\n",
    "    np.hstack([mu_test.detach().numpy(), np.zeros((len(mu_test), 3))])\n",
    ")[:, :2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e2bbb6-f89b-40da-a692-4dd3d3e149f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================\n",
    "# Step 7: Historical Graph\n",
    "# =============================\n",
    "df_last_12m = df_product.sort_values('Date').tail(12)\n",
    "month_labels_hist = [f\"{calendar.month_name[d.month]}-{d.year}\" for d in df_last_12m['Date']]\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(month_labels_hist, df_last_12m['Quantity Sold (liters/kg)'], marker='o', label=\"Actual Sales\")\n",
    "plt.plot(month_labels_hist, df_last_12m['Reorder Quantity (liters/kg)'], marker='o', label=\"Actual Demand\")\n",
    "plt.title(f\"Historical Sales & Demand (Last 12 Months) for {product_name.title()}\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Quantity\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786f85ad-1f0f-4810-b27d-f819b3dae022",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================\n",
    "# Step 6.5: Recursive Forecast\n",
    "# =============================\n",
    "days_ahead = months_ahead * 30\n",
    "future_preds = []\n",
    "\n",
    "last_sequence = X_test[-1].unsqueeze(0)\n",
    "\n",
    "for _ in range(days_ahead):\n",
    "    with torch.no_grad():\n",
    "        mu_next, _ = model(last_sequence)\n",
    "        future_preds.append(mu_next.squeeze(0).numpy())\n",
    "\n",
    "        next_seq = torch.cat(\n",
    "            [last_sequence[:, 1:, :], \n",
    "             torch.cat([mu_next, last_sequence[:, -1, 2:]], dim=1).unsqueeze(1)],\n",
    "            dim=1\n",
    "        )\n",
    "        last_sequence = next_seq\n",
    "\n",
    "future_preds = np.array(future_preds)\n",
    "future_preds = scaler.inverse_transform(\n",
    "    np.hstack([future_preds, np.zeros((len(future_preds), 3))])\n",
    ")[:, :2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddf3588-6067-4a18-b1d0-393f1f045794",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================\n",
    "# Step 8: Monthly Aggregation\n",
    "# =============================\n",
    "monthly_preds = []\n",
    "for i in range(months_ahead):\n",
    "    monthly_preds.append(\n",
    "        future_preds[i*30:(i+1)*30].mean(axis=0)\n",
    "    )\n",
    "monthly_preds = np.array(monthly_preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c484da58-fc01-469a-a0b4-fcff042cfe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# Step 9: Print Forecast\n",
    "# =============================\n",
    "now = datetime.now()\n",
    "print(f\"\\n{months_ahead}-Month Forecast\\n\")\n",
    "\n",
    "for i in range(months_ahead):\n",
    "    month = (now.month + i - 1) % 12 + 1\n",
    "    year = now.year + (now.month + i - 1) // 12\n",
    "    print(\n",
    "        f\"{calendar.month_name[month]}-{year}: \"\n",
    "        f\"Sales = {monthly_preds[i,0]:.2f}, \"\n",
    "        f\"Demand = {monthly_preds[i,1]:.2f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4e81a3-1beb-4076-9150-69d986ccdc80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f66f53-6956-4ed6-a1c7-ddde7952d56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4587bef-255f-40e6-bd94-0b87d0d22fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7a352c-f84b-4745-8348-73172a2eb846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe920d-6064-41d1-8674-772d320d3f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc52de6-a501-40c9-bff3-f22d9707dbcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b88a5ea-11d4-40ec-8931-80fe04f5b0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
